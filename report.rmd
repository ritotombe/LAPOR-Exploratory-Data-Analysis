LAPOR! EDA by Septi Rito Tombe
========================================================

```{r echo=FALSE, message=FALSE, warning=FALSE, packages}
library(ggplot2)
library(knitr)
library(dplyr)
library(gridExtra)
library(ggmap)
library(lubridate)
library(anytime)
library(grid)
library(GGally)
library(psych)
```

```{r global_options, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, 
                      warning=FALSE,
                      message=FALSE, 
                      fig.width = 10, 
                      fig.height = 15)
```

```{r echo=FALSE, Load_the_Data}
# Load the Data
df <- read.csv('data/total.csv') 
```

# Introduction
This data fetched from http://data.go.id/dataset/data-aspirasi-dan-pengaduan-masyarakat. It contains reports from Indonesian citizens by a platform called LAPOR!. This platform enables the officials to solve public issues that posted by citizens and it also inform the citizen if the issue was solved. Originally, the data was consist of two csvs, the first csv (data.csv) contains the report's content and its attributes such as creator, area, and category. The other csv (daftararea.csv), contains the area details including its latitude and longitude. Eventually, the csvs was merged based on "area" as shown in the *wrangle.R* file. However, some attributes were **deleted** because it contains redundancy with the other attributes or may contains sensitive materials, such attribute is the report's content.

The rationale behind this data is to explore the usage of the platform. Some questions may be answered through the analysis such as:
1. When is the reports most frequently posted?
2. Proportion of solved reports.
3. Where are mostly the reports originated?
4. Are there any interesting value regarding th idle time of each report?
5. etc... (I intent to create 5W + 1H questions as necessary as possible while exploring the data)

This report will contain four main sections. The first three section will contain univariate, bivariate, and multivariate data exploration. Finally, the last section will summarise all the findings and present a reflection. 

# Univariate Plots Section

```{r echo=FALSE, Data_Summary_1}
dim(df)
```
```{r echo=FALSE, Data_Summary_2}
str(df)
```

```{r echo=FALSE, Data_Summary_3}
summary(df)
```

Below are the overall overview of the dataset

```{r echo=FALSE, Overall_Report_Proportion, fig.height = 5}
df.group_by_status <- group_by(df, status)

df.status_count <- 
  summarise(df.group_by_status,
            n = n(),
            proportion = round(n()/nrow(df.group_by_status)*100,3))

#https://www.statmethods.net/graphs/pie.html
labels <- paste(c("Waiting", "In Progress", "Finished"), 
                df.status_count$proportion)
labels <- paste(labels, "%", sep=" ")
pie(df.status_count$n, 
    labels = labels, 
    main = "Report Status Proportion")
```

As shown in the chart, the reports are mostly finished (Selesai) and less than 1% is still waiting to be processed. I wonder, when are these reports issued.

```{r echo=FALSE, Univariate_Plots, fig.height = 5}
#https://stackoverflow.com/questions/17496358/r-help-converting-factor-to-date
#https://stackoverflow.com/questions/22603847/how-to-extract-month-from-date-in-r
#https://stackoverflow.com/questions/13456241/convert-unix-epoch-to-date-object
df$report_issued.month <- month(anydate(df$report_issued))
df$report_issued.year <- year(anydate(df$report_issued))
df$report_issued.day <- weekdays(anydate(df$report_issued))

not_processed <- subset(df, status == 'Belum')

q1 <- qplot(data = df, 
            x = report_issued.month, 
            binwidth = 1,
            color = I('white')) +
        scale_x_continuous(breaks = seq(1, 12, 1)) + 
        theme(axis.text.x = element_text(angle = 90, hjust = 1))

q2 <- qplot(data = df, 
            x = report_issued.year, 
            binwidth = 1, 
            color = I('white')) +
        scale_x_continuous(breaks = seq(2009, 2016, 1)) + 
        theme(axis.text.x = element_text(angle = 90, hjust = 1))

q3 <- qplot(data = df,
            x = report_issued.day, 
            color = I('white')) +
        scale_x_discrete(limits =  c('Monday', 
                                   'Tuesday', 
                                   'Wednesday', 
                                   'Thursday', 
                                   'Friday', 
                                   'Saturday', 
                                   'Sunday')) + 
        theme(axis.text.x = element_text(angle = 90, hjust = 1))

q4 <- qplot(data = not_processed, 
            x = report_issued.month, 
            binwidth = 1, 
            color = I('white'))+
        scale_x_continuous(breaks = seq(1, 12, 1)) + 
        theme(axis.text.x = element_text(angle = 90, hjust = 1))

q5 <- qplot(data = not_processed,
            x = report_issued.year, 
            binwidth = 1, 
            color = I('white') )+
        scale_x_continuous(breaks = seq(2009, 2016, 1)) + 
        theme(axis.text.x = element_text(angle = 90, hjust = 1))

q6 <- qplot(data = not_processed, 
            x = report_issued.day, 
            color = I('white')) +
        scale_x_discrete(limits =  c('Monday', 
                                     'Tuesday', 
                                     'Wednesday', 
                                     'Thursday', 
                                     'Friday', 
                                     'Saturday', 
                                     'Sunday')) + 
        theme(axis.text.x = element_text(angle = 90, hjust = 1))

grid.arrange(textGrob("All Status"), 
             q1, q2, q3, 
             textGrob("Waiting"), 
             q4, q5, q6, 
             ncol = 4, 
             top = "Number of Reports Issued (Issue Time)" )
```

As shown on the histograms above, there are some similarities and differences between the overall status and the waiting data. The similarities can be found in monthly and daily basis, such as the highest report issued in January and least reports issued on weekends. In the other hand, on yearly basis it shows the graphs are contradicted. This make me wonder how long it typically an issue to be solved? I will cover this in Bivariate section.

Furthermore, lets check another time series variables. Such last activity, I wonder how long typically an acitvity being idle/processed (report_last_activity != report_closed).

```{r echo=FALSE, Waiting_Time, fig.height = 5}
df$idle_time <- df$report_last_activity - df$report_issued

df$idle_time.month <- df$idle_time/60/60/24/30

df$idle_time.day <- df$idle_time/60/60/24

q1 <- qplot(data =  subset(df, 
                           report_closed != report_last_activity), 
            x = idle_time.month,  
            binwidth = 1, 
            color =  I("white")) + 
        scale_x_continuous(limits = c(0,
                                      quantile(df$idle_time.month, 0.99)), 
                           breaks = seq(0,
                                        quantile(df$idle_time.month, 0.99), 
                                        1)) +
        labs(title = "Waiting/Processing Time (monthly basis)", 
             x = "number of month(s)")

q2 <- qplot(data =  subset(df,
                           report_closed != report_last_activity), 
            x = idle_time.day, binwidth = 50, 
            color = I("white")) + 
        labs(title = "Waiting/Processing Time (daily basis)", 
             x = "number of day(s)")

grid.arrange(q1, q2)
```

The histogram is highly skewed showing that time for waiting to be processed/processed time is relatively low. However, there are outliers indicated by longtail to be investigated. Furthermore, there is something interesting in the daily basis of waiting time, it shows increasing towards 500, while before it reach a slope.

```{r echo=FALSE, Subset_Summary}
summary(subset(df$idle_time.day, df$idle_time.day >= 0))
```

I want to investigate the report_closed, when mostly the reports finished.

```{r echo=FALSE, Univariate_Plots_2, fig.height = 10}
df$report_closed.month <- month(anydate(df$report_closed))
df$report_closed.year <- year(anydate(df$report_closed))
df$report_closed.day <- weekdays(anydate(df$report_closed))


q1 <- qplot(data = df, 
            x = report_closed.month, 
            binwidth = 1, 
            color = I('white')) +
        scale_x_continuous(breaks = seq(1, 12, 1))

q2 <- qplot(data = df, 
            x = report_closed.year, 
            binwidth = 1, 
            color = I('white')) +
        scale_x_continuous(breaks = seq(2009, 2016, 1))

q3 <- qplot(data = df, 
            x = report_closed.day, 
            color = I('white')) +
        scale_x_discrete(limits =  c('Monday', 
                                     'Tuesday', 
                                     'Wednesday', 
                                     'Thursday', 
                                     'Friday', 
                                     'Saturday', 
                                     'Sunday'))

grid.arrange(q1, q2, q3, 
             top = "Number of Reports Closed (Issue Time)" )
```

As shown, there are some unusual distribution on the daily histogram, lowest activity presented in Friday and Saturday. In contrast, In general in Indonesia, weekend are Saturday and Sunday. The monthly data shows that mostly reports closed in March and November.

# Univariate Analysis

### What is the structure of your dataset?
The data consists of 79565 reports in 2012-2015. Originally, the data consist of 11 features; eventually, the data expanded to 17 features.

### What is/are the main feature(s) of interest in your dataset?
The main features of the data is the report is the *status*, *area*, *idle_time* and the time series (*report_issued*, *report_last_activity*, and *report_closed*). I intend to investigate areas that have best response in time and finished rate. Furthermore, I also want to investigate the same thing with the *related_department*. 

### What other features in the dataset do you think will help support your\investigation into your feature(s) of interest?
Additional features like the duration between issued time vs closed time would be a good feature to answer the questions. Moreover, with latitude and longitude I can visualise the data to be more comprehensive in map.

### Did you create any new variables from existing variables in the dataset?
Yes, I created count of each status to find proportion. I also created some new features regarding the time data. For example, the report_issued.month is purposed to group the data into montly basis. Another example is idle_time indicating duration between report_issued and report_last_activity.

### Of the features you investigated, were there any unusual distributions? \ Did you perform any operations on the data to tidy, adjust, or change the form \ of the data? If so, why did you do this?
There is unusual distribution shown in Waiting status, it is contrasting with the overall status. The waiting status shows the data to be declining; in contrast, the overall data shows to be increasing. Another unusual distribution also found in monthly issued data, it shows mostly reports were issued in January. Another anomaly also shown in reports closed on day basis, it is interesting that there is no reports closed in Saturday but there are some reports closed on Sunday. It is interesting because the reports should closed by the officials that should be not working on Sunday. (However, I still unsure maybe if the user delete the report, it also counted as report closed)

There are some actions was conducted to adjust the data. For example, there are some negative values in the duration timeseries, it might be caused by null values in the one of the feature, thus, in visualisation and summary I limit the data from 0. This was done to reduce confusion in presenting the data. 


# Bivariate Plots Section

Here I want to get insights from factors variables. I have three factor variables that I supposed may have meaning (reporter, category, related_department). Nevertheless, these variables has a high degree of level. Thus, I need to subset it to most common ones (50 or 100 levels) for the sake of readability. To do that, I want to create variables of these factors' levels' counts and sort it descending.

``` {r echo=FALSE, Features_Generation}
df.area_count <- count(df, area)
df.area_count <- df.area_count[order(-df.area_count$n),]
df$area.ordered <- ordered(df$area, levels = df.area_count$area)
df.area_count <- df.area_count[1:50,]

df.reporter_count <- count(df, reporter)
df.reporter_count <- df.reporter_count[order(-df.reporter_count$n),]
df$reporter.ordered <- ordered(df$reporter, levels = df.reporter_count$reporter)
df.reporter_count <- df.reporter_count[1:100,]

df.category_count <- count(df, category)
df.category_count <- df.category_count[order(-df.category_count$n),]
df$category.ordered <- ordered(df$category, levels = df.category_count$category)
df.category_count <- df.category_count[1:50,]


df.related_department_count <- count(df, related_department)
df.related_department_count <- 
df.related_department_count[order(-df.related_department_count$n),]
df$related_department.ordered <- ordered(df$related_department, levels = df.related_department_count$related_department)
df.related_department_count <- df.related_department_count[1:50,]


```

At first, I want to see the distribution of these variables to the idle time.

```{r echo=FALSE, Time_to_Wait_Based_on_Area}
 ggplot(data = subset(df, area %in% df.area_count$area), 
        aes(y = area.ordered, 
            x = idle_time.day)) + 
  geom_point(alpha = .1) +
  scale_x_continuous(breaks = seq(0, 5000, 100)) +
  labs(x = 'Waiting Time', 
       y = "Area", 
       title = 'Time to Wait/Area') 
```

I guess, this figure shows that the daily basis waiting time's anomaly. In detail, there are some provinces and cities that have similar pattern (high completion around 0-100 and 400-500). But still, I wonder are there any variables that produces same pattern?

```{r echo=FALSE, Time_to_Wait_Based_on_Category}
 ggplot(data = subset(df, category %in% df.category_count$category), 
        aes(y = category.ordered, 
            x = idle_time.day)) + 
  geom_point(alpha = .1) +
  scale_x_continuous( breaks = seq(0, 5000, 50)) +
  labs(x = 'Waiting Time', 
       y = "Category", 
       title = 'Time to Wait/Category') + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

In regards of the categories, it is interesting that there are some categories that shows high variability in term of duration to finish it. For example (the plot should be enlarged to find all category), Jamkesmas, Raskin, ESDM, and BLSM. However, it does not produce same pattern as earlier plot. Let see 
another variables.

```{r echo=FALSE, Time_to_Wait_Based_on_Reporter}
ggplot(data = subset(df, reporter %in% df.reporter_count$reporter), aes(y = reporter.ordered, x = idle_time.day)) + 
  geom_point(alpha = .1) +
  scale_x_continuous(breaks = seq(0, 5000, 100)) +
  labs(x = 'Waiting Time', y = "Reporter", title = 'Time to Wait/Reporter') 
```

There is something special here for user "6281680xxxx ", it seems his/her report mostly done in a long duration (I think it has the same fashion as the daily basis waiting time anomaly). Let see what is it? (Below is an univariate plot, I put it here to keep the flow)

```{r echo=FALSE, Reporter_anomaly, fig.height = 5}
ggplot(data = subset(df, reporter == '6281680xxxx '), 
       aes(x = category.ordered)) + 
  geom_bar(alpha = .5) +
  labs(x = 'Category', 
       y = "Count", 
       title = 'User 6281680xxxx Categories') + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

Apparently, there are two categories that may done in long period which are, *Topik Lainnya* (other topic) and *Lingkungan hidup dan penanggulangan bencana* (Enviromental and Disaster Countermeasures), both of them are enlisted as top 10 report category. I think, it because the clarity of the report content so it requires time to determine which department that has to deal with it, or it supposed to took long time to resolve a disaster.

I want to continue at the main variables first before I dive too deep for this user.

```{r echo=FALSE, Time_to_Wait_Based_on_Department}
ggplot(data = subset(df, 
                     related_department %in% 
                       df.related_department_count$related_department), 
       aes(y = related_department.ordered, x = idle_time.day)) + 
  geom_point(alpha = .05) +
  scale_x_continuous(breaks = seq(0, 5000, 200)) +
  labs(x = 'Waiting Time', 
       y = "Related Department", 
       title = 'Time to Wait/Department') 
```

It seems there is no similar pattern with the previous charts.However I want to see the relation between waiting time and when the reports issued

```{r echo=FALSE, Duration_To_Finish, fig.height = 5}
ggplot(data = df, aes(y = idle_time.day, 
                      x = report_issued.day)) + 
  geom_bin2d() +
  scale_y_continuous(limits = c(0, quantile(df$idle_time.day, 0.68)), 
                     breaks = seq(0, 30, 1)) +
  scale_x_discrete(limits =  c('Monday', 
                               'Tuesday', 
                               'Wednesday', 
                               'Thursday', 
                               'Friday', 
                               'Saturday', 
                               'Sunday')) + 
  labs(x = 'Day of the Reports Issued', 
       y = 'Duration of Waiting Time to Finish', 
       title = 'Day Issued vs Duration to Finish')

```

It is interesting that this shows that every weekend there are small amount of reports finished, although there are some which might be urgent reports. However, on most case, reports are done only in one day (see Monday - Thursday), while on Friday, whether they intend to finish it in same day or on Monday after the weekends. Furthermore, on Saturday and Sunday, it seems there is very little report, thus there is no significant number of common duration. Furthermore, I want to see the relations between numerical values such as report_closed, report_issued, and idle_time.

**Correlation**
```{r echo=FALSE, Correlation}
cor(df$report_issued, df$report_closed, method = "pearson")
cor(df$report_issued, df$idle_time, method = "pearson")
cor(df$report_closed, df$idle_time, method = "pearson")
```

**Scatterplots**

I will try to use log10 transformation on the idle_time.day to normalise the data.

```{r echo=FALSE, Scatterplots, fig.height = 5}
q1 <- ggplot(data = df, aes(y = report_issued, 
                            x = report_closed)) + 
  geom_point(alpha = .1) +
  labs(x = 'Time Closed (Epoch Time)', 
       y = "Time Issued (Epoch Time)", 
       title = 'Time Issued vs Time Solved for each Issue') 
 
q2 <- ggplot(data = subset(df, !is.na(log10(idle_time.day+1))), 
             aes(y = report_issued, x = idle_time.day+1)) + 
  geom_point(alpha = .05) +
  coord_trans(x = 'sqrt') +
  labs(y = 'Time Issued (Epoch Time)', 
       x = "Waiting Time to Finish (days)", 
       title = 'Time Issued vs Waiting Time for each Issue') 

grid.arrange(q1,q2)
```

It seems report_issued and report_closed have a high correlation, which may mean the reports relatively done in shorter time. This was also confirmed with the other plot that shows there is very small (almost none) correlation between the report_issued and idle_time. Furthermore, the plot shows that the waiting time relatively small. However, there are some cases that the finish time are somehow clustered on ~500 days. I want to see what time exactly it is.

```{r echo=FALSE, Anomaly, fig.height = 5}
 ggplot(data = subset(df, !is.na(log10(idle_time.day+1))), 
        aes(y = report_issued, 
            x = idle_time.day+1)) + 
  geom_point(alpha = .05) +
  coord_trans(x = 'sqrt') +
  scale_x_continuous(limits= c(400, 500)) +
  labs(y = 'Time Issued (Epoch Time)', 
       x = "Waiting Time to Finish (days)", 
       title = 'Time Issued vs Waiting Time for each Issue') 
```

```{r echo=FALSE, Time_of_Anomaly}
#https://www.tutorialspoint.com/r/r_mean_median_mode.htm
getmode <- function(v) {
   uniqv <- unique(v)
   uniqv[which.max(tabulate(match(v, uniqv)))]
}

mean(subset(df, idle_time.day > 400 & idle_time.day < 500)[,'report_issued'])
median(subset(df, idle_time.day > 400 & idle_time.day < 500)[,'report_issued'])
getmode(subset(df, idle_time.day > 400 & idle_time.day < 500)[,'report_issued'])

```

Respectively, above are the mean, median, and mode of the previous plot. When I tried to convert the timestamp into local time (GMT+7) and did some research on Google, I found that on these months (July-Aug 2013) there was some natural disasters occured. Which confirmed another previous plots that shows anomaly in range of ~500 idle time. I wonder why it took too long (almost 2 years to solve). Either it were not updated until it closed automatically, or the issues truly took almost 2 years to be resolved.
Ref:
 - https://www.epochconverter.com/timezones?q=1376629673&tz=Asia%2FJakarta
 - https://reliefweb.int/report/indonesia/indonesia-humanitarian-snapshot-july-august-2013

# Bivariate Analysis

### Talk about some of the relationships you observed in this part of the \ investigation. How did the feature(s) of interest vary with other features in \ the dataset?
In this section, I mostly explore the relation of *idle_time*/waiting time with the other attributes. It is interesting that the other attribute may have impact or pattern with the waiting time.

### Did you observe any interesting relationships between the other features \ (not the main feature(s) of interest)? What was the strongest relationship you found?
As I mentioned before, I mostly explore the relation between *idle_time* and the other features. However, I also tried to see relationship between *report_issued* and *report_closed*. I found that the reports mostly finished in relatively short time.

# Multivariate Plots Section

In this section I want to visualise the data in a map to gain better understanding via geographical picture. But first, I want to look indepth about the user 6281680xxxx to comprehensive exploration about the issue.

```{r echo=FALSE, Years_Time_to_Wait}
ggplot(data = subset(df, 
                     reporter %in% 
                       df.reporter_count$reporter), 
       aes(y = reporter.ordered, 
           x = idle_time.day, 
           color = factor(report_issued.year))) + 
  geom_point(alpha = .5) +
  scale_x_continuous(breaks = seq(0, 5000, 100)) +
  labs(x = 'Waiting Time', 
       y = "Reporter", 
       title = 'Time to Wait/Reporter Year Based', 
       colour ="Year Issued") +
  scale_color_brewer(palette = 'Spectral')
```

It seems the report mostly issued on 2013-2014. However, it seems very little data for 2012. In the other hand, 2015 reports are commonly done earlier. Furthermore, I want to see where are commonly this reporter issuing the reports.

```{r echo=FALSE, Reporting_Area, fig.height = 5}
#https://stackoverflow.com/questions/19307896/using-ggplots-ggmap-function-to-superimpose-two-maps-on-top-of-each-other

jkt_map <- ggmap(get_googlemap(center=c(106.7652727,-6.2359827), 
                               scale=1, 
                               zoom=10), 
                 extent="normal")

jkt_map +
  geom_point(data = subset(df, reporter == '6281680xxxx '), 
             aes(y = latitude, x = longitude, color = idle_time.day), 
             alpha = .5) +
  scale_colour_gradient(low = 'blue', high = 'red')+
  labs(x = 'Longitude', 
       y = "Latitude", 
       title = 'Reporter 6281680xxxx Reporting Area', colour ="Idle Time Issued") 
```

It seems it only around Jakarta. However, the longer idle time seems clustered into a certain point. It may indicating he she reporting a same issue overtime.
I am getting over my curiosity about this user, as I move on to general distribution of the data.

```{r echo=FALSE, Time_Issued, fig.height = 5}

indo_map <- ggmap(get_googlemap(center=as.numeric(geocode("Indonesia")), 
                                scale=1, 
                                zoom=4), 
                  extent="normal")
indo_map +
  geom_point(data = subset(df, idle_time.day > quantile(idle_time.day, 0.90)), 
             aes(y = latitude, x = longitude, colour = idle_time.day), 
             alpha = .5) +
  lims(y = c(-10,6), x = c(95,140)) +
  scale_colour_gradient(low = 'yellow', 
                        high = 'black') +
  labs(x = 'Longitude', 
       y = "Latitude", 
       title = 'Time to Wait/Area', colour ="Idle Time Issued")

```

As seen in the graph, the fastest response area is located in East Java and slowest ones are Celebes, 
Borneo, and North Sumatera. Furthermore, the status mapping.

```{r echo=FALSE, Last, fig.height = 5}
indo_map +
  geom_point(data = subset(df, idle_time.day > quantile(idle_time.day, 0.90)), 
             aes(y = latitude, x = longitude, colour = status), 
             alpha = .5) +
  lims(y = c(-10,6), 
       x = c(95,140)) +
  scale_colour_brewer(palette = 'Set2')  +
  labs(x = 'Longitude', 
       y = "Latitude",
       title = 'Status Over Area', colour ="Status")
```

The chart shows that mostly the data are done. However in some area, there are balanced proportion between 'Processing' and 'Done' such as at the Island Sumatera and Island Halmahera.

# Multivariate Analysis

### Talk about some of the relationships you observed in this part of the \investigation. Were there features that strengthened each other in terms of \looking at your feature(s) of interest?
Yes, especially for the user 6281680xxxx, it shows where are the reports' origin that took too long be finished.

### Were there any interesting or surprising interactions between features?
The data are scattered on the regional area. For example, in summary, the proportion of the finished reports are way too high compared with the other status; however, it seems just because data are highly clustered in Island Java, while in the other Islands the proportion seems not so distinct.

------

# Final Plots and Summary

### Plot One
```{r echo=FALSE, Plot_One, fig.height = 5}
qplot(data =  subset(df, 
                     report_closed != report_last_activity), 
      x = idle_time.day, 
      binwidth = 25, 
      color = I("white"), 
      fill = I('#0c304a')) + 
  scale_x_continuous(limits = c(0,600), 
                     breaks = seq(0, 600, 25)) +
  labs(title = "Processing Time (daily basis)", 
       x = "Number of Day(s)")
```

### Description One
In this chart, it is interesting that there are some data that finished on a long period (> 300 days). 

### Plot Two
```{r echo=FALSE, Plot_two, fig.height = 5}
options(scipen=999)
 ggplot(data = subset(df, 
                      !is.na(log10(idle_time.day+1))), 
        aes(y = report_issued, 
            x = idle_time.day+1, 
            color = '#fffbcc')) + 
  geom_point(alpha = .05) +
  coord_trans(x = 'sqrt') +
  scale_x_continuous(limits= c(400, 500)) +
  scale_y_continuous(breaks = seq(1350000000, 1425000000, 25000000), 
                     labels=c("October 12, 2012", 
                              "July 28, 2013 ", 
                              "May 13, 2014",
                              'February 27, 2015')) +
  labs(y = 'Time Issued', 
       x = "Waiting Time to Finish (days)", 
       title = 'Time Issued vs Waiting Time for each Issue')  + 
  theme(legend.position="none")
```

### Description Two
Eventually, I found one user that have a similar pattern to that anomaly. It shows there are some reports clustered in 400-500 days duration. Thus, I am curious about when are these reports issued. I found that these data are issued on these months (July-Aug 2013). 

### Plot Three
```{r echo=FALSE, Plot_Three, fig.height = 5}
indo_map +
  geom_point(data = subset(df, 
                           idle_time.day > quantile(idle_time.day, 0.90)), 
             aes(y = latitude, 
                 x = longitude, 
                 colour = factor(status, 
                                 labels = c("Belum (Not Yet)",
                                            "Proses (In Progress)",
                                            "Selesai (Done)"))), 
             alpha = .5) +
  lims(y = c(-10,6), 
       x = c(95,140)) +
  scale_colour_brewer(palette = 'Set2') +
  labs(x = 'Longitude', 
       y = "Latitude", 
       title = 'Status Over Area', colour ="Status")
```

### Description Three
Finally, I found an anomaly on the status of the reports, it seems propotions of 'Done' and 'In Progess' are different among islands. It seems the data are clustered at Java with mostly 'Done'. However, in the other islands such as Sumatera, Borneo, and Halmahera has indistinct difference.

------

# Reflection
I am collecting my data from a data repository. Originally, I have no knowledge about the data that being used in this analysis and there is no particular intention why I am using this data, it was simply because I saw it as available data that comply with the requirements. Furthermore, I thought there will be only a little information that I can extract from the data because I do not know the relation between the features. 

However, it took a long time to be able work with this dataset. There are bad values here and there, which led me took longer time compared to if I am using the prepared dataset. It made me understands that data wrangling and cleaning took mostly the time for analysis. In addition, I have to took a long contemplation to understand connection between features and which combinations that may convey meaning and value. 

Thus, I have came up with some different ways to exploit the data. It was suprising that I can some unique findings (such as the waiting time duration anomaly), because at first I was pessimist about the data will show any significant value. These make me thought for the future, that I should have a better understanding about the data that I am going to dive in. I think this will save time of the contemplation.Eventually, I realised these all are only part of a great exploration.
